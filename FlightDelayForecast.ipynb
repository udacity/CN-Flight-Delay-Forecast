{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 项目: 机票航班延误预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "欢迎来到机票航班延误预测的实战项目！在此文件中，有些示例代码已经提供给你，但你还需要实现更多的功能让项目成功运行。除非有明确要求，你无须修改任何已给出的代码。以**'练习'**开始的标题表示接下来的代码部分中有你必须要实现的功能。每一部分都会有详细的指导，需要实现的部分也会在注释中以'TODO'标出。请仔细阅读所有的提示！\n",
    "\n",
    "除了实现代码外，你还必须回答一些与项目和你的实现有关的问题。每一个需要你回答的问题都会以**'问题 X'**为标题。请仔细阅读每个问题，并且在问题后的**'回答'**文字框中写出完整的答案。我们将根据你对问题的回答和撰写代码所实现的功能来对你提交的项目进行评分。\n",
    ">**提示：**Code 和 Markdown 区域可通过**Shift + Enter**快捷键运行。此外，Markdown可以通过双击进入编辑模式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始\n",
    "\n",
    "我们知道，航班延误对于旅客、售卖机票的平台以及航空公司都是一个比较头疼的问题。造成航班延误的因素有很多，包括台风、雾霾、飞机故障、航空管制等等原因。在这个项目中，我们将探索在飞机起飞前2小时做航班延误预测这个实际问题，你将从实际问题出发，探索数据，抽取数据特征，构建模型并作出预测。\n",
    "\n",
    "这个项目的数据来自[航班动态起降数据集](https://www.kesci.com/home/dataset/59793a5a0d84640e9b2fedd3)（数据集由和鲸社区提供），该数据集用2015年5月到2017年5月的机场情况作为训练集，用201年6月作为测试集。你可以通过报名该比赛获取数据集，另外，为了方便大家获取数据，我们也提供了一个[下载地址](https://static-documents.s3.cn-north-1.amazonaws.com.cn/nd101/MLND+documents/data.zip)，请下载后放置data文件夹中。\n",
    "\n",
    "**数据说明：**\n",
    "\n",
    "\n",
    "- ./data/2015年5月到2017年5月城市天气.csv\n",
    "- ./data/2015年5月到2017年5月航班动态数据.csv\n",
    "- ./data/2015年5月到2017年5月特情.xlsx\n",
    "- ./data/机场城市对应表.xlsx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 运行下面区域的代码以载入一些此项目所需的Python库。如果成功返回提示语句，则说明载入成功。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为这个项目导入需要的库\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print('你已经成功载入所需要的库！')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据初探"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入数据\n",
    "我们先导入数据，然后观察头部数据。可以使用[read_csv](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html), [read_excel](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html) 分别加载对应格式的数据，然后使用[head](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.head.html)观察前5条数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文件路径 './data/2015年5月到2017年5月航班动态数据.csv'\n",
    "# 注意使用字符编码 encoding=\"gb2312\"\n",
    "# TODO: 根据以上提示信息，导入航班数据\n",
    "flight_data = \n",
    "\n",
    "# 文件路径 \"./data/2015年5月到2017年5月城市天气.csv\"\n",
    "# TODO：根据以上提示信息，导入天气数据\n",
    "weather = \n",
    "\n",
    "# 文件路径 \"./data/机场城市对应表.xlsx\"\n",
    "# TODO：根据以上提示信息，导入城市与机场对应数据\n",
    "airport_city = \n",
    "\n",
    "# 文件路径 \"./data/2015年5月到2017年5月特情.xlsx\"\n",
    "# TODO：根据以上提示信息，导入特情数据\n",
    "special ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 观察数据\n",
    "使用 [head](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.head.html)观察前5条数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 观察航班数据\n",
    "flight_data.head()\n",
    "\n",
    "# 观察天气数据\n",
    "weather.head()\n",
    "\n",
    "# 通过观察，发现有一列没有用的空表格 “Unnamed: 5”，你需要使用 `del` 将其从 `weather` 数据中删除\n",
    "del weather[\"Unnamed: 5\"]\n",
    "\n",
    "# 观察城市与机场对应数据\n",
    "airport_city.head()\n",
    "\n",
    "# 观察特情数据\n",
    "spcial.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 问题1：我们知道，一个有监督学习问题是总有一个需要预测的目标值，那么在这个问题中，你通过了解此问题的背景以及观察以上的数据，认为此任务中的目标值是什么？在已有的数据中，给出了预测目标值吗？如果没有的话，我们要如何获得这个目标值呢？\n",
    "\n",
    "回答问题："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 整理targets值\n",
    "\n",
    "根据以上对数据的初步观察，我们发现，这样的实际问题的数据是非常不规整的。数据的targets标签并没有显式地给出，而是需要自己整理。在这一小节，我们根据飞行数据 `flight_data` 整理出我们需要的targets。\n",
    "\n",
    "我们首先定义延误时间：实际起飞时间与计划起飞时间的差；然后，我们以延误时长是否超过3小时来定义targets。同时观察到“航班是否取消”这一列数据，针对数据中的“取消”的航班，我们直接可以将其延误时间设置成12小时。\n",
    "\n",
    "**建议**：用[numpy.where](https://numpy.org/devdocs/reference/generated/numpy.where.html?highlight=where#numpy.where)按条件选择延误时间是否超过三小时，如果超过三小时则延误目标值取1，否则延误目标值取0；另外也用[numpy.where](https://numpy.org/devdocs/reference/generated/numpy.where.html?highlight=where#numpy.where)按条件选择`flight_data['航班是否取消']`是否为 `取消`,如果是取消则直接可以将其延误时间设置成12小时。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO：计算 起飞延误时间，以小时为单位，注意将单位秒转换为单位小时\n",
    "flight_data['起飞延误时间'] = \n",
    "\n",
    "\n",
    "# TODO：`light_data['航班是否取消']是否为 “取消”,如果是取消则直接可以将其延误时间设置成12小时\n",
    "flight_data[\"飞机延误目标\"] = \n",
    "\n",
    "flight_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 整理简单features\n",
    "\n",
    "在课程中，所讲解的案例使用的是比较干净的数据集，然而在真实业务场景里，却很少有直接可用的数据，我们往往需要从复杂的数据中提取重要的特征来帮助我们解决实际问题。正如当前所做的项目，我们无法直接使用所有数据，而是需要进行数据归并、删选、提取重要的特征。\n",
    "\n",
    "在整理完我们的目标值之后，我们可以开始进行特征工程。根据以上的几个文件，我们可以得到很多特征，在这里，我们先抽取一个简单的特征，学习一遍在处理实际数据时的特征工程流程。\n",
    "\n",
    "我们所抽取的特征是 `weather`中的“天气”数据。但我们发现 `weather` 中的数据并不是直接可用的，而是需要我们将该天气数据按照日期和城市对齐至飞行数据`flight_data`中。具体来说，我们参考下面的图片![merge_data](./figure/merge_feature.png)\n",
    "\n",
    "- 我们先要将天气 `weather`中的“城市”一列的数据，通过机场城市`airport_city`数据中的“城市名称”和“城市编码”，将 `weather`中的“城市”转化为“城市编码”，这样才能跟`flight_data`中的机场编码对应上。\n",
    "- 然后我们要将 `weather`中的“日期”一列的数据对齐至`flight_data`中“计划起飞时间”上。但是，我们发现“计划起飞时间”是以秒为单位的浮点格式数据，因此我们还需要将“计划起飞时间”转换成和`weather`中的“日期”一样的时间格式。\n",
    "\n",
    "接下来就是按以上的步骤进行操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，利用 [merge](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html) ，按`airport_city`中的城市名称和城市编码，将 `weather`中的城市名称转化为城市编码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 将机场编码对应到天气数据上面，根据城市名，注意 weather 数据是【城市】，而 airport_city 是【城市名称】\n",
    "airport_weather = \n",
    "\n",
    "# # 去除缺失值和重复的机场天气信息\n",
    "airport_weather = airport_weather.dropna()\n",
    "airport_weather = airport_weather.drop_duplicates(['日期','机场编码'])\n",
    "airport_weather.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们发现，数据`airport_weather`中的“日期”格式和`flight_data`中的“计划起飞时间”格式是不一致的，为了能够将机场天气数据`airport_weather`按照“日期”归并至飞行数据`flight_data`中，我们首先需要将`flight_data`中的“计划起飞时间”格式转化成年月日统一格式。可以先用[to_datetime](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_datetime.html)将浮点类型的数据转化为日期格式，然后再将日期格式的数据转化为 统一的 年月日格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO：利用 to_datetime  浮点类型的数据转化为时间数据，单位为秒，utc时间为True\n",
    "flight_data['计划起飞日期tmp'] = \n",
    "\n",
    "# 再将日期格式的数据转化为 统一的 年月日格式。\n",
    "flight_data['计划起飞日期'] = flight_data['计划起飞日期tmp'].apply(lambda x:x.strftime('%Y-%m-%d') if not(pd.isnull(x)) else None)\n",
    "flight_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后，再次利用[merge](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html)，根据机场名称和日期信息，将机场天气`weather`数据对应到飞行数据 `flight_data` 中。注意，`flight_data`中是“出发机场”和“计划起飞日期”,而 `airport_weather`中对应的是“机场编码”和“日期”。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: merge flight_data 和 airport_weather\n",
    "flight_data =\n",
    "flight_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立简单模型\n",
    "\n",
    "### 特征处理\n",
    "我们可以先建立一个最简单的模型，从飞行数据`flight_data`中挑选2列数据作为features，其中一个是我们刚刚构造好的“天气”数据，另外一个feature由你来选择。注意，其中“飞机延误时间”和“飞机延误目标”并不是feature，而是targets，所以不能选择这两列作为features。\n",
    "\n",
    "#### 问题2：你选择的特征是特征是什么？说说你选择这个feature的理由。\n",
    "\n",
    "回答问题："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 选择一列数据作为feature\n",
    "features = [\"天气\"]\n",
    "add_to_feature =   # 你选择的feature\n",
    "features.append(add_to_feature)\n",
    "data = flight_data[features]\n",
    "\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO：从 flight_data 中取出目标\"飞机延误目标\"的值，numpy格式的值\n",
    "targets = \n",
    "\n",
    "# train_data 的数据量和 targets 的数据量一定是相等的\n",
    "assert len(data) == len(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "到这里，我们已经提取完并得到两个特征，但是现在的特征是非数值类型的，那么我们需要先对这些非数值类型的特征进行编码。\n",
    "\n",
    "从上面的**数据探索**中的表中，我们可以看到有几个属性的每一条记录都是非数字的。通常情况下，学习算法期望输入是数字的，这要求非数字的特征（称为类别变量）被转换。转换类别变量的一种流行的方法是使用**独热编码**方案。独热编码为每一个非数字特征的每一个可能的类别创建一个_“虚拟”_变量。例如，假设`someFeature`有三个可能的取值`A`，`B`或者`C`，。我们将把这个特征编码成`someFeature_A`, `someFeature_B`和`someFeature_C`.\n",
    "\n",
    "| 特征X |                    | 特征X_A | 特征X_B | 特征X_C |\n",
    "| :-: |                            | :-: | :-: | :-: |\n",
    "|  B  |  | 0 | 1 | 0 |\n",
    "|  C  | ----> 独热编码 ----> | 0 | 0 | 1 |\n",
    "|  A  |  | 1 | 0 | 0 |\n",
    "\n",
    "因此，**独热编码**将会对特征进行扩维，例如上面对例子，将对单个特征`someFeature` 扩充成3个特征`someFeature_A`, `someFeature_B`和`someFeature_C`，这种独热编码，你可以参考one-hot[get_dummies](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html) 解释和实现以及使用。\n",
    "\n",
    "另一种对非数值类型对特征进行编码对方法是直接对字符编号，例如 `someFeature` 由 1.0、2.0、3.0 来作为特征值进入模型对计算。更进一步来说，这种方法如果类型比较多对话，将会导致特征空间太离散，影响模型对建模性能。于是我们需要对这些数值进行归一化，针对该问题，在我们实际业务场景中经常使用对解决方案是使用的编码方式是 [sklearn.preprocessing.LabelEncoder.fit_transform](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html#sklearn.preprocessing.LabelEncoder.fit_transform)，它会将离散的字符映射到一个数值，用以表示该特征并参与模型计算。\n",
    "\n",
    "\n",
    "#### 问题3：请参考文档简单介绍一下 `LabelEncoder.fit_transform`，说一下该方法和独热表示one-hot[get_dummies](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html)有什么区别，并根据刚刚构造好对`天气`特征包含对类别数量等统计信息来回答这里为什么用 `fit_transform`？\n",
    "\n",
    "回答问题："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "判断数据中是否存在缺省值的情况，如果存在，请处理缺省值。\n",
    "\n",
    "建议，你可以通过 `any(isnull())`[isnull](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.isnull.html)去判断数据中是否存在缺失情况；然后通过[fillna](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html)去填补缺省值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO：判断并处理`data`中的缺省值\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "string_encoder = preprocessing.LabelEncoder()\n",
    "# 我们首先对天气特征的进行编码\n",
    "data[\"天气\"] = string_encoder.fit_transform(data[\"天气\"])\n",
    "\n",
    "# TODO：对你选择的特征进行编码，如果你选择的是数值类型的特征，那么你可以按照前面所学知识进行归一化等处理\n",
    "data[add_to_feature] = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型构建\n",
    "\n",
    "现在我们可以根据上面构造好的feature和target来构建一个简单的模型。\n",
    "\n",
    "- 第一步：使用`sklearn.model_selection.train_test_split`按**0.2**的测试比例切分训练集和测试集；\n",
    "- 第二步：继续使用`sklearn.model_selection.train_test_split`按**0.2**的测试比例切分训练集和测试集；\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入 train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 将'data'和'targets'数据切分成训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, targets, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# 将'X_train'和'y_train'进一步切分为训练集和验证集\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "# 显示切分的结果\n",
    "print (\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "print (\"Validation set has {} samples.\".format(X_val.shape[0]))\n",
    "print (\"Testing set has {} samples.\".format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 监督学习模型\n",
    "### 模型应用\n",
    "\n",
    "你能够在 [`scikit-learn`](http://scikit-learn.org/stable/supervised_learning.html) 中选择以下监督学习模型\n",
    "- 高斯朴素贝叶斯 (GaussianNB)\n",
    "- 决策树 (DecisionTree)\n",
    "- 集成方法 (Bagging, AdaBoost, Random Forest, Gradient Boosting)\n",
    "- K近邻 (K Nearest Neighbors)\n",
    "- 随机梯度下降分类器 (SGDC)\n",
    "- 支撑向量机 (SVM)\n",
    "- Logistic回归（LogisticRegression）\n",
    "\n",
    "\n",
    "\n",
    "#### 问题4: 从上面的监督学习模型中选择两个适合我们这个问题的模型，并回答相应问题。然后从中选择一个先在我们等数据集上进行训练和测试，这一步是为了初步感受模型在此数据集上等表现。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型1\n",
    "\n",
    "**模型名称**\n",
    "\n",
    "回答：\n",
    "\n",
    "\n",
    "**描述一个该模型在真实世界的一个应用场景。（你需要为此做点研究，并给出你的引用出处）**\n",
    "\n",
    "回答：\n",
    "\n",
    "**这个模型的优势是什么？他什么情况下表现最好？**\n",
    "\n",
    "回答：\n",
    "\n",
    "**这个模型的缺点是什么？什么条件下它表现很差？**\n",
    "\n",
    "回答：\n",
    "\n",
    "**根据我们当前数据集的特点，为什么这个模型适合这个问题。**\n",
    "\n",
    "回答："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型2\n",
    "\n",
    "**模型名称**\n",
    "\n",
    "回答：\n",
    "\n",
    "\n",
    "**描述一个该模型在真实世界的一个应用场景。（你需要为此做点研究，并给出你的引用出处）**\n",
    "\n",
    "回答：\n",
    "\n",
    "**这个模型的优势是什么？他什么情况下表现最好？**\n",
    "\n",
    "回答：\n",
    "\n",
    "**这个模型的缺点是什么？什么条件下它表现很差？**\n",
    "\n",
    "回答：\n",
    "\n",
    "**根据我们当前数据集的特点，为什么这个模型适合这个问题。**\n",
    "\n",
    "回答："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 评价模型性能\n",
    "在这一部分中，我们选择上面两个模型之一来训练。\n",
    "\n",
    "在这个，分类预测问题中，我们使用**准确率**作为评价模型等标准，同时能够使用**F-beta score**作为评价指标，这样能够同时考虑查准率和查全率：\n",
    "\n",
    "$$ F_{\\beta} = (1 + \\beta^2) \\cdot \\frac{precision \\cdot recall}{\\left( \\beta^2 \\cdot precision \\right) + recall} $$\n",
    "\n",
    "\n",
    "尤其是，当 $\\beta = 0.5$ 的时候更多的强调查准率，这叫做**F$_{0.5}$ score** （或者为了简单叫做F-score）。\n",
    "\n",
    "\n",
    "由于数据量比较大，模型训练可能需要一些时间来运行！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO：从sklearn中导入两个评价指标 - fbeta_score和accuracy_score\n",
    "from sklearn.metrics import fbeta_score, accuracy_score\n",
    "\n",
    "# TODO：从sklearn中导入上面你选择等一个监督学习模型\n",
    "\n",
    "\n",
    "# TODO：设置模型参数，初始化这个模型\n",
    "\n",
    "# TODO：在训练集 X_train, y_train 上训练该模型\n",
    "\n",
    "# TODO：在验证集 X_val, y_val 上预测并计算socre fbeta_score和accuracy_score\n",
    "\n",
    "f_score = \n",
    "acc = \n",
    "\n",
    "# 打印 fbeta_score和accuracy_score\n",
    "print(\"Train and valid successed. F-score: {}, Acc: {}\".format(f_score, acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 问题5： 用通俗的话解释模型\n",
    "\n",
    "*用一到两段话，用外行也听得懂的话来解释最终模型是如何工作的。你需要解释所选模型的主要特点。例如，这个模型是怎样被训练的，它又是如何做出预测的。避免使用高级的数学或技术术语，不要使用公式或特定的算法名词。*\n",
    "\n",
    "回答问题："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 练习：模型调优\n",
    "调节选择的模型的参数。使用网格搜索（GridSearchCV）来至少调整模型的重要参数（至少调整一个），这个参数至少需尝试3个不同的值。你要使用整个训练集来完成这个过程。在接下来的代码单元中，你需要实现以下功能：\n",
    "\n",
    "- 导入[`sklearn.model_selection.GridSearchCV`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) 和 [`sklearn.metrics.make_scorer`](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html).\n",
    "- 初始化你选择的分类器，并将其存储在`clf`中。\n",
    " - 设置`random_state` (如果有这个参数)。\n",
    "- 创建一个对于这个模型你希望调整参数的字典。\n",
    " - 例如: parameters = {'parameter' : [list of values]}。\n",
    " - **注意：** 如果你的学习器有 `max_features` 参数，请不要调节它！\n",
    "- 使用`make_scorer`来创建一个`fbeta_score`评分对象（设置$\\beta = 0.5$）。\n",
    "- 在分类器clf上用'scorer'作为评价函数运行网格搜索，并将结果存储在grid_obj中。\n",
    "- 用训练集（X_train, y_train）训练grid search object,并将结果存储在`grid_fit`中。\n",
    "\n",
    "**注意：** 取决于你选择的参数列表，下面实现的代码可能需要花一些时间运行！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO：导入'GridSearchCV', 'make_scorer'和其他一些需要的库\n",
    "\n",
    "# TODO：初始化分类器\n",
    "clf = None\n",
    "\n",
    "# TODO：创建你希望调节的参数列表\n",
    "parameters = None\n",
    "\n",
    "# TODO：创建一个fbeta_score打分对象\n",
    "scorer = None\n",
    "\n",
    "# TODO：在分类器上使用网格搜索，使用'scorer'作为评价函数\n",
    "grid_obj = None\n",
    "\n",
    "# TODO：用训练数据拟合网格搜索对象并找到最佳参数\n",
    "\n",
    "# 得到estimator\n",
    "best_clf = grid_obj.best_estimator_\n",
    "\n",
    "# 使用没有调优的模型做预测\n",
    "predictions = (clf.fit(X_train, y_train)).predict(X_val)\n",
    "best_predictions = best_clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征重要性分析\n",
    "在做数据分析过程中，我们需要分析抽取出来的特征对预测的贡献，以得出特征的重要性。特征重要性分析能够帮助我们继续进行相关的特征工程，比如过滤一些没有贡献的特征，加强一些比较重要的特征。\n",
    "\n",
    "\n",
    "选择一个`scikit-learn`中有`feature_importance_`属性的监督学习分类器，这个属性是一个在做预测的时候根据所选择的算法来对特征重要性进行排序的功能。\n",
    "\n",
    "在下面的代码单元中，你将要实现以下功能：\n",
    " - 如果这个模型和你前面使用的三个模型不一样的话从sklearn中导入一个监督学习模型。\n",
    " - 在整个训练集上训练一个监督学习模型。\n",
    " - 使用模型中的 `'feature_importances_'`提取特征的重要性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO：导入一个有'feature_importances_'的监督学习模型\n",
    "\n",
    "# TODO：在训练集上训练一个监督学习模型，初始化\n",
    "model = None\n",
    "# TODO: fit 训练集\n",
    "model.fit()\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "features = [\"weather\", \"your feature\"]\n",
    "\n",
    "feature_important = model.feature_importances_\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.bar(np.arange(len(features)),feature_important)\n",
    "plt.xticks(np.arange(len(features)),features,fontsize=12,rotation=10)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 问题6：哪一个特征更加重要？这符合你的直觉吗？谈谈你在平时的项目中在做特征工程时，对于使用符合直觉的特征的看法，可以举例说明。\n",
    "\n",
    "回答问题："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型对比\n",
    "\n",
    "目前为止，我们已经对一个实际问题的复杂的数据进行了处理，并抽取了一两个特征，然后进行了模型训练。你可以按照这个流程做更多的特征工程的工作。由于数据量大，我们已经做好了特征工程，同时我们也sample了部分数据，方便接下来对不同模型进行比较。\n",
    "\n",
    "这一小节，我们要学习在具体业务场景经常使用的模型，梯度提升决策树 （Gradient Boosting Decison Tree，GBDT）。GBDT在工业场景和各大数据挖掘比赛中都是非常流行的模型，在这里，我们尝试对这些流行对模型进行初探。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 问题7：通俗的解释什么是 梯度提升决策树 （Gradient Boosting Decison Tree，GBDT）？并列举其优缺点。\n",
    "\n",
    "回答问题："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 问题8：目前比较流行的 `GBDT`的变种有 [Xgboost](https://xgboost.readthedocs.io/en/latest/) 和 [LightGBM](https://lightgbm.readthedocs.io/en/latest/)，请比较这三个梯度提升模型，列举他们各自的特点? （你可以参考一些文档，并给出你的引用出处）\n",
    "\n",
    "回答问题："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们已经预先对该数据做了充分的特征工程，然后 `sample` 出了部分数据。数据在路径 `./data/`下面，有训练集`train.csv`和测试集`test.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 直接运行读取数据，并分别得到 X 和 Y 的数据\n",
    "\n",
    "# 处理训练集\n",
    "train_x = pd.read_csv(\"./data/train.csv\")\n",
    "train_y = train_x[\"飞机延误目标\"].values\n",
    "del(train_x[\"飞机延误目标\"])\n",
    "# 处理测试集\n",
    "test_x = pd.read_csv(\"./data/test.csv\")\n",
    "test_y = test_x[\"飞机延误目标\"].values\n",
    "del(test_x[\"飞机延误目标\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对 gbdt 进行调参\n",
    "\n",
    "按照上面简单模型构建部分的流程，先定义一个梯度提升决策树分类器 GradientBoostingClassifier，并设置里面固定参数；然后设置需要调优的参数，然后通过 网格搜索 `GridSearchCV` 进行搜索最优参数。由于数据量已经减少，这里你可以将参数设置的大一些，以提升模型的准确度，但要防止过拟合。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "\n",
    "# TODO: 需要调的参数，比如 max_depth, n_estimators, learning_rate\n",
    "cv_params = \n",
    "\n",
    "\n",
    "#TODO：设置 GBDT 分类器 GradientBoostingClassifier\n",
    "model = \n",
    "# TODO: 设置 GridSearchCV\n",
    "grid_cv = \n",
    "# TODO: 模型训练\n",
    "grid_cv.fit(train_x, train_y)\n",
    "\n",
    "# TODO：在测试集上预测，并计算accuracy和f-score\n",
    "\n",
    "\n",
    "# TODO：打印最优参数\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对 Xgboost 进行调参\n",
    "关于xgboost 的参数设置和调参与gbdt类似，参数也是类似的，比如 `n_estimators`表示树的个数；`max_depth`表示构建树的深度，越大越容易过拟合；`gamma`表示用于控制是否后剪枝的参数；`reg_lambda`是用来控制模型复杂度的L2正则化的参数，值越大，模型越不容易过拟合，等等。由于数据量已经减少，这里你可以将参数设置的大一些，以提升模型的准确度，但要防止过拟合。\n",
    "\n",
    "如果没有安装过xgboost，你需要先运行以下代码来安装 xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 使用Xgboost 进行训练和测试\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "# TODO: 选择要调优的参数, 比如max_depth, n_estimator,learning_rate\n",
    "cv_params =\n",
    "model = \n",
    "\n",
    "grid_cv = \n",
    "grid_cv.fit(train_x, train_y)\n",
    "\n",
    "\n",
    "# TODO：在测试集上预测，并计算准确率\n",
    "\n",
    "# TODO：预测测试集的结果\n",
    "predict_y = \n",
    "# TODO：计算 准确率\n",
    "\n",
    "auc=\n",
    "# 打印准确率结果\n",
    "print(\"准确率：{}\".format(auc))\n",
    "\n",
    "# TODO：打印最优参数\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 问题9：在这个任务中，`GBDT`和`xgboost`的性能如何？哪一个更优？通过此次对比和调参过程，总结你对**梯度提升决策树**调参的经验与总结\n",
    "\n",
    "回答问题："
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
